{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing Custom Image Classification Model\n",
    "\n",
    "In this lab, you will evolve the custom image classification model developed in Lab1:\n",
    "\n",
    "Developed | Cultivated | Barren\n",
    "--------- | ------ | ----------\n",
    "![Developed](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/developed1.png) | ![Cultivated](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/cultivated1.png) | ![Barren](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/barren1.png)\n",
    "\n",
    "Forested | Grassland | Shrub\n",
    "---------| ----------| -----\n",
    "![Forested](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/forest1.png) | ![Grassland](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/grassland1.png) | ![Shrub](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/shrub1.png)\n",
    "\n",
    "You will utilize a custom image classifier using a Deep Learning technique called *Fine-tuning*. *Fine-tuning* is a flavor of Transfer learning (demonstrated in Lab 1).\n",
    "\n",
    "In fine-tuning, you remove the last layer(s) (usually the FCNN layers) of the pre-trained network and replace it with the new untrained layers that match the given ML task. You than re-train the full-network (pre-trained \"trunk\" and new top) using images from your custom domain. It is also a common practice to freeze the weights of the first few layers of the pre-trained network. This is because these layers capture universal features like curves and edges that are also relevant to the new problem. You want to keep those weights intact. Instead, you \"force\" the network to focus on learning dataset-specific features in the subsequent layers.\n",
    "\n",
    "Since *fine-tuning* is much more computationally intensive than transfer learning approach used in Lab 1, we will train the network using the Horovod distributed training algorithm. Azure Machine Learning provides built-in support for Horovod that simpliefies cluster configuration and job scheduling.\n",
    "\n",
    "![Fine-tuning](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/fine-tune.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the lab dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "azcopy --source https://azureailabs.blob.core.windows.net/aerialsmall --destination /tmp/datasets/aerialsmall --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "ls -l /tmp/datasets/aerialsmall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to AML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the dataset to the default Datastore\n",
    "\n",
    "We will upload the dataset to the default Datastore to make it available to all nodes in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "\n",
    "ds.upload(src_dir='/tmp/datasets/aerialsmall', target_path='aerialsmall', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure ML Managed Compute\n",
    "\n",
    "To run the lab's scripts we will utilize Azure ML managed compute resources. Specifically, an autoscale cluster of *Standard_NC6* VMs (equipped with Tesla K80 GPU). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "\n",
    "# choose a name for your cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"gpu-cluster\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 1)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"Standard_NC6\")\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
    "                                                                min_nodes = compute_min_nodes, \n",
    "                                                                max_nodes = compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "     # For a more detailed view of current AmlCompute status, use the 'status' property    \n",
    "    print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "### Pre-training\n",
    "\n",
    "Before you can retrain the weights in the base network it is recommend to pre-train the new top with all weights in the base network frozen. We will run pretraining for a few epochs on a single node of the cluster.\n",
    "\n",
    "#### Create training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_folder/pre-train.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten, Input\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.applications import vgg16\n",
    "\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "\n",
    "# Create custom callback to track accuracy measures in AML Experiment\n",
    "class RunCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, run):\n",
    "        self.run = run\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.run.log(name=\"training_acc\", value=float(logs.get('acc')))\n",
    "        self.run.log(name=\"validation_acc\", value=float(logs.get('val_acc')))\n",
    "\n",
    "\n",
    "def custom_classifier(input_shape=(224,224,3), units=256, classes=6,  l1=0.01, l2=0.01, optimizer='adadelta'):\n",
    "    # Create a base vgg16 model\n",
    "    base_model = vgg16.VGG16(\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        pooling='avg')\n",
    "    # Add new top\n",
    "    x = base_model.output\n",
    "    x = Dense(units, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    y = Dense(classes, activation='softmax', kernel_regularizer=l1_l2(l1=l1, l2=l2))(x)\n",
    "    model = Model(inputs=base_model.inputs, outputs=y)\n",
    "    \n",
    "    return model, base_model\n",
    "       \n",
    "\n",
    "def main(argv=None):\n",
    "    \n",
    "    \n",
    "    print(\"Loading data from:\", FLAGS.data_folder)\n",
    "    # Create training and validation data generators\n",
    "    train_data_dir = os.path.join(FLAGS.data_folder, 'train')\n",
    "    valid_data_dir = os.path.join(FLAGS.data_folder, 'valid')\n",
    "     \n",
    "    # A hack to mitigate a bug in TF.Keras 1.12\n",
    "    def preprocess_input_new(x):\n",
    "        img = vgg16.preprocess_input(image.img_to_array(x))\n",
    "        return image.array_to_img(img)\n",
    "    \n",
    "    batchsize=64\n",
    "    classes = [\"Barren\", \"Cultivated\", \"Developed\", \"Forest\", \"Herbaceous\", \"Shrub\"]\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_new)\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        directory=train_data_dir,\n",
    "        target_size=(224, 224),\n",
    "        classes=classes,\n",
    "        batch_size=batchsize)\n",
    "\n",
    "    valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_new)\n",
    "    valid_generator = train_datagen.flow_from_directory(\n",
    "        directory=valid_data_dir,\n",
    "        target_size=(224, 224),\n",
    "        classes=classes,\n",
    "        batch_size=batchsize)\n",
    "    \n",
    "    print(len(train_generator))\n",
    "    print(len(valid_generator))\n",
    "    \n",
    "    \n",
    "    # Create a custom model\n",
    "    model, base_model = custom_classifier()\n",
    "    \n",
    "    # freeze all base model layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Use adadelta optimizer for pretraining the top layer\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = 'adadelta',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    # Configure callbacks to generate Tensorboard and AML logs\n",
    "    run = Run.get_submitted_run()\n",
    "    callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "                 RunCallback(run)]\n",
    "    \n",
    "    # Start training\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=FLAGS.epochs,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=len(valid_generator))\n",
    "    \n",
    "    # Save the trained model to outputs which is a standard folder expected by AML\n",
    "    print(\"Training completed.\")\n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    model_file = os.path.join('outputs', 'aerial_model_pretrain.h5')\n",
    "    weights_file = os.path.join('outputs', 'aerial_model_weights_pretrain.h5')\n",
    "    print(\"Saving model to: {0}\".format(model_file))\n",
    "    model.save(model_file)\n",
    "    print(\"Saving model weights to: {0}\".format(weights_file))\n",
    "    model.save_weights(weights_file)\n",
    " \n",
    "\n",
    "# Default global parameters\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_integer('batch_size', 32, \"Number of images per batch\")\n",
    "tf.app.flags.DEFINE_integer('epochs', 10, \"Number of epochs to train\")\n",
    "tf.app.flags.DEFINE_integer('units', 512, \"Number of epochs to train\")\n",
    "tf.app.flags.DEFINE_string('data_folder', 'aerialsmall', \"Folder with images\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create AML Experiment\n",
    "We will track pre-traning in a dedicated Experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "experiment_name = 'aerial-finetune-pretrain'\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run a pre-training on a single node of the cluster\n",
    "\n",
    "We will use *TensorFlow* estimator. *TensorFlow* estimator automatically configures the runtime image with all required pre-requisites - TensorFlow, CUDA, etc.\n",
    "\n",
    "Due to time limitations of the lab, we will run pre-training for 3 epochs only. Note that in a real production scenario you would want to run pre-training for more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import TensorFlow\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "\n",
    "script_params = {\n",
    "    '--data_folder': ds.path('aerialsmall').as_mount(),\n",
    "    '--epochs': 3\n",
    "}\n",
    "\n",
    "pip_packages = ['h5py', 'pillow', 'scipy']\n",
    "\n",
    "est = TensorFlow(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                entry_script='pre-train.py',\n",
    "                use_gpu=True,\n",
    "                pip_packages=pip_packages\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {\"Run Type\": \"Top pre-train\"}\n",
    "run = exp.submit(est, tags=tags)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitor the run with Tensorboard\n",
    "\n",
    "Azure Machine Learning has a built-in support for **Tensorboard**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.tensorboard import Tensorboard\n",
    "tb = Tensorboard([run])\n",
    "tb.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect to Tensorboard navigate to `http://<external IP of your DSVM>:6006`. If you have issues connecting, double check that you opened port 6006 as described in the lab set up instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can cancel the run with the `cancel` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or block till the run completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve weights\n",
    "\n",
    "The training scripts saves the weights of the pre-trained model into the `outputs` folder. This folder is automatically copied to the *Experiment* after the run completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run.get_file_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.download_file('outputs/aerial_model_weights_pretrain.h5', '/tmp/models/aerial_model_weights_pretrain.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "ls /tmp/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload the weights to the default datastore\n",
    "\n",
    "The fine tuning script (below) will download the pre-trained weights from the default datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the dataset to the DataStore\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "ds.upload(src_dir='/tmp/models', target_path='models', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning\n",
    "\n",
    "We are now ready to run distributed training on AML Compute cluster.\n",
    "\n",
    "#### Create training script\n",
    "\n",
    "The training script uses Horovod API to coordinate distributed training. In addition to the top layers, we will also re-train the last convolutional layer in the base VGG16 network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_folder/fine-tune.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten, Input\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import horovod.tensorflow.keras as hvd\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "# Create custom callback to track accuracy measures in AML Experiment\n",
    "class RunCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, run):\n",
    "        self.run = run\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.run.log(name=\"training_acc\", value=float(logs.get('acc')))\n",
    "        self.run.log(name=\"validation_acc\", value=float(logs.get('val_acc')))\n",
    "\n",
    "\n",
    "        \n",
    "def custom_classifier(input_shape=(224,224,3), units=256, classes=6,  l1=0.01, l2=0.01, optimizer='adadelta'):\n",
    "    # Create a base vgg16 model\n",
    "    base_model = vgg16.VGG16(\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        pooling='avg')\n",
    "    # Add new top\n",
    "    x = base_model.output\n",
    "    x = Dense(units, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    y = Dense(classes, activation='softmax', kernel_regularizer=l1_l2(l1=l1, l2=l2))(x)\n",
    "    model = Model(inputs=base_model.inputs, outputs=y)\n",
    "    \n",
    "    return model, base_model\n",
    "    \n",
    "\n",
    "def main(argv=None):\n",
    "    \n",
    "    \n",
    "    # Initialize Horovod\n",
    "    hvd.init()\n",
    "    \n",
    "    # Horovod: pin GPU to be used to process local rank (one GPU per process)\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.gpu_options.visible_device_list = str(hvd.local_rank())\n",
    "    tf.keras.backend.set_session(tf.Session(config=config))\n",
    "\n",
    "    print(\"Initialized Horovod\")\n",
    "    \n",
    "    print(\"Loading data from:\", FLAGS.data_folder)\n",
    "    # Create training and validation data generators\n",
    "    train_data_dir = os.path.join(FLAGS.data_folder, 'train')\n",
    "    valid_data_dir = os.path.join(FLAGS.data_folder, 'valid')\n",
    "    \n",
    "    # A hack to mitigate a bug in TF.Keras 1.12\n",
    "    def preprocess_input_new(x):\n",
    "        img = vgg16.preprocess_input(image.img_to_array(x))\n",
    "        return image.array_to_img(img)\n",
    "    \n",
    "    # Configure training and validation data generators\n",
    "    batchsize=64\n",
    "    classes = [\"Barren\", \"Cultivated\", \"Developed\", \"Forest\", \"Herbaceous\", \"Shrub\"]\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_new)\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        directory=train_data_dir,\n",
    "        target_size=(224, 224),\n",
    "        classes=classes,\n",
    "        batch_size=batchsize)\n",
    "\n",
    "    valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_new)\n",
    "    valid_generator = train_datagen.flow_from_directory(\n",
    "        directory=valid_data_dir,\n",
    "        target_size=(224, 224),\n",
    "        classes=classes,\n",
    "        batch_size=batchsize)\n",
    "    \n",
    "    print(len(train_generator))\n",
    "    print(len(valid_generator))\n",
    "    \n",
    "    \n",
    "    # Create a custom model\n",
    "    model, base_model = custom_classifier()\n",
    "    \n",
    "    # Load the weights pretrained in the previous step on the first worker, \n",
    "    # which will broadcast them to other workers.\n",
    "    if hvd.rank() == 0:\n",
    "        weights_file = os.path.join(FLAGS.weights_folder, FLAGS.weights_filename)\n",
    "        model.load_weights(weights_file)\n",
    "        print(\"------------------------------------\")\n",
    "        print(\"Loaded pre-trained weights on Rank 0\")\n",
    "    \n",
    "    # Make last convolutional layer trainable\n",
    "    for layer in base_model.layers[:14]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    for layer in base_model.layers[14:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Wrap an optimizer in Horovod\n",
    "    # For fine tuning use SGD with a low learning rate\n",
    "    optimizer = hvd.DistributedOptimizer(optimizers.SGD(lr=1e-4, momentum=0.9))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = optimizer,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    # Configure callbacks\n",
    "    callbacks = [\n",
    "        # Horovod: broadcast initial variable states from rank 0 to all other processes.\n",
    "        # This is necessary to ensure consistent initialization of all workers when\n",
    "        # training is started with loaded weights.\n",
    "        hvd.callbacks.BroadcastGlobalVariablesCallback(0),\n",
    "\n",
    "        # Horovod: average metrics among workers at the end of every epoch.\n",
    "        #\n",
    "        # Note: This callback must be in the list before the ReduceLROnPlateau,\n",
    "        # TensorBoard, or other metrics-based callbacks.\n",
    "        hvd.callbacks.MetricAverageCallback()\n",
    "\n",
    "    ]\n",
    "            \n",
    "    # Horovod: save checkpoints only on worker 0 to prevent other workers from corrupting them.\n",
    "    # Configure Tensorboard and Azure ML Tracking\n",
    "    if hvd.rank() == 0:\n",
    "        callbacks.append(tf.keras.callbacks.ModelCheckpoint('./checkpoint-{epoch}.h5'))\n",
    "        callbacks.append(tf.keras.callbacks.TensorBoard(log_dir='./logs'))\n",
    "        run = Run.get_submitted_run()\n",
    "        callbacks.append(RunCallback(run))\n",
    "   \n",
    "    model.summary()\n",
    "    \n",
    "    # Start trining\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator)//hvd.size(),\n",
    "        epochs=FLAGS.epochs,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=3*len(valid_generator)//hvd.size(),\n",
    "        callbacks=callbacks)\n",
    "    \n",
    "    # Save the trained model to outputs folder on the first worker\n",
    "    if hvd.rank() == 0:  \n",
    "        print(\"Training completed.\")\n",
    "        os.makedirs('outputs', exist_ok=True)\n",
    "        model_file = os.path.join('outputs', 'aerial_model_fine_tune.h5')\n",
    "        model.save(model_file)\n",
    "\n",
    "\n",
    "# Default global parameters\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_integer('batch_size', 32, \"Number of images per batch\")\n",
    "tf.app.flags.DEFINE_integer('epochs', 10, \"Number of epochs to train\")\n",
    "tf.app.flags.DEFINE_integer('units', 512, \"Number of epochs to train\")\n",
    "tf.app.flags.DEFINE_string('data_folder', 'aerialsmall', \"Folder with images\")\n",
    "tf.app.flags.DEFINE_string('weights_folder', 'models', \"Folder with model weights\")\n",
    "tf.app.flags.DEFINE_string('weights_filename', 'aerial_model_weights_pretrain.h5', \"Folder with model weights\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    " \n",
    "    tf.app.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create AML Experiment\n",
    "We will track the Horovod runs in a dedicated experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "experiment_name = 'aerial-finetune-train'\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run a fine-tuning training on  the cluster\n",
    "\n",
    "*TensorFlow* estimator encapsulates idiosyncrasies of Horovod cluster configuration and job scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "from azureml.train.dnn import TensorFlow\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "\n",
    "script_params = {\n",
    "    '--data_folder': ds.path('aerialsmall').as_mount(),\n",
    "    '--weights_folder': ds.path('models').as_download(),\n",
    "    '--epochs': 7\n",
    "}\n",
    "\n",
    "# We need to install the up to date version of Horovod\n",
    "# since the version in a standard AML GPU image does not support\n",
    "# horovod.tensorflow.keras\n",
    "pip_packages = ['h5py', 'pillow', 'scipy', 'horovod']\n",
    "\n",
    "est = TensorFlow(source_directory=script_folder,\n",
    "                      compute_target=compute_target,\n",
    "                      script_params=script_params,\n",
    "                      entry_script='fine-tune.py',\n",
    "                      node_count=3,\n",
    "                      process_count_per_node=1,\n",
    "                      distributed_backend='mpi',\n",
    "                      use_gpu=True,\n",
    "                      pip_packages=pip_packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {\"Run Type\": \"Top pre-train\"}\n",
    "run = exp.submit(est, tags=tags)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
