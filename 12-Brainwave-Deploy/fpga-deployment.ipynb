{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE\n",
    "\n",
    "*We have recently experienced issues with `azureml.contrib.brainwave` library. Till the issues are addressed we are suspending development of FPGA labs. These are the labs with **1x** prefix*.\n",
    "\n",
    "\n",
    "# FPGA Deployment\n",
    "\n",
    "In this lab you will deploy the custom image classification model developed in Lab 1 to an FPGA powered cloud services.\n",
    "\n",
    "Project Brainwave is a hardware architecture from Microsoft. It's based on Intel's FPGA devices, which data scientists and developers use to accelerate real-time AI calculations. This FPGA-enabled architecture offers performance, flexibility, and scale, and is available on Azure.\n",
    "\n",
    "FPGAs make it possible to achieve low latency for real-time inferencing requests. Asynchronous requests (batching) aren't needed. Batching can cause latency, because more data needs to be processed. Project Brainwave implementations of neural processing units don't require batching; therefore the latency can be many times lower, compared to CPU and GPU processors.\n",
    "\n",
    "You can reconfigure FPGAs for different types of machine learning models. This flexibility makes it easier to accelerate the applications based on the most optimal numerical precision and memory model being used. Because FPGAs are reconfigurable, you can stay current with the requirements of rapidly changing AI algorithms.\n",
    "\n",
    "Today, Project Brainwave supports:\n",
    "\n",
    "- Image classification and recognition scenarios\n",
    "- TensorFlow deployment\n",
    "- DNNs: ResNet 50, ResNet 152, VGG-16, SSD-VGG, and DenseNet-121\n",
    "- Intel FPGA hardware\n",
    "\n",
    "Using this FPGA-enabled hardware architecture, trained neural networks run quickly and with lower latency. Project Brainwave can parallelize pre-trained deep neural networks (DNN) across FPGAs to scale out your service. The DNNs can be pre-trained, as a deep featurizer for transfer learning, or fine-tuned with updated weights.\n",
    "\n",
    "To deploy FPGA service you need to:\n",
    "- Create a service definition\n",
    "- Register the model \n",
    "- Deploy the service with the registered model\n",
    "\n",
    "\n",
    "# Note\n",
    "\n",
    "*Brainwave* requires TensorFlow 1.10. Currently, DSVM includes TensorFlow 1.12. To run the lab you need to downgrade TensorFlow in `py36` environment on DSVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to AML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "import os\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model\n",
    "\n",
    "### Create a service definition\n",
    "\n",
    "A service definition is a file describing a pipeline of graphs (input, featurizer, and classifier) based on TensorFlow. The deployment command automatically compresses the definition and graphs into a ZIP file, and uploads the ZIP to Azure Blob storage. The DNN is already deployed on Project Brainwave to run on the FPGA.\n",
    "\n",
    "Here we use the TF.Keras model trained in the lab 1 in the classifier stage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the top model from the model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Retrieve the model file\n",
    "model_name = 'aerial_classifier_brainwave'\n",
    "model_path = Model.get_model_path(model_name, _workspace=ws)\n",
    "\n",
    "# Rehydrate the model\n",
    "model = load_model(model_path)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a service\n",
    "\n",
    "Define input tensors node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.contrib.brainwave.models.utils as utils\n",
    "in_images = tf.placeholder(tf.string)\n",
    "image_tensors = utils.preprocess_array(in_images)\n",
    "print(image_tensors.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define **resnet50** featurizer. It has to be the same model as used in Lab1 to create bottleneck features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.brainwave.models import QuantizedResnet50\n",
    "model_path = os.path.expanduser('~/models')\n",
    "bwmodel = QuantizedResnet50(model_path, is_frozen = True)\n",
    "print(bwmodel.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the FPGA pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.brainwave.pipeline import ModelDefinition, TensorflowStage, BrainWaveStage, KerasStage\n",
    "\n",
    "model_def = ModelDefinition()\n",
    "model_def.pipeline.append(TensorflowStage(tf.Session(), in_images, image_tensors))\n",
    "model_def.pipeline.append(BrainWaveStage(tf.Session(), bwmodel))\n",
    "model_def.pipeline.append(KerasStage(model))\n",
    "\n",
    "model_def_path = './model_def'\n",
    "model_def.save(model_def_path)\n",
    "print(model_def_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy\n",
    "\n",
    "Register with model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n",
    "model_name = \"aerial-classifier-brainwave\"\n",
    "service_name = \"aerial-brainwave-service\"\n",
    "\n",
    "registered_model = Model.register(ws, model_def_path, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import Webservice\n",
    "from azureml.exceptions import WebserviceException\n",
    "from azureml.contrib.brainwave import BrainwaveWebservice, BrainwaveImage\n",
    "try:\n",
    "    service = Webservice(ws, service_name)\n",
    "except WebserviceException:\n",
    "    image_config = BrainwaveImage.image_configuration()\n",
    "    deployment_config = BrainwaveWebservice.deploy_configuration()\n",
    "    service = Webservice.deploy_from_model(ws, service_name, [registered_model], image_config, deployment_config)\n",
    "    service.wait_for_deployment(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the service\n",
    "\n",
    "The *Brainwave* library includes a simple client that can be used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.brainwave.client import PredictionClient\n",
    "client = PredictionClient(service.ipAddress, service.port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.ipAddress + ':' + str(service.port))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
